# =============================================================================
# 环境配置示例 (复制到 .env 并填写密钥和配置)
# =============================================================================

# =============================================================================
# 路径配置
# =============================================================================

# 数据输出根目录 (每次运行会在此目录下创建时间戳子文件夹)
DATA_BASE_DIR=data
# 日志输出目录
LOG_DIR=logs
# 参考音频目录
REF_DIR=ref
# 模型检查点目录
CHECKPOINTS_DIR=checkpoints

# =============================================================================
# LLM 翻译配置 (OpenAI API)
# =============================================================================

# OpenAI API 密钥 (必需)
OPENAI_API_KEY=YOUR_API_KEY
# API 基础 URL (可选，默认 https://api.openai.com/v1)
# 可用于自定义端点或兼容 API
OPENAI_BASE_URL=https://api.openai.com/v1
# 翻译使用的模型名称
MODEL_NAME=gpt-4o
# HTTP 代理 (可选，用于下载和 LLM 调用)
# PROXY=http://127.0.0.1:7890

# =============================================================================
# 视频下载配置 (yt-dlp)
# =============================================================================

# 视频 URL (可选，也可通过命令行 --url 传入)
VIDEO_URL=
# 本地视频文件路径 (跳过下载，直接使用本地文件)
LOCAL_VIDEO=
# 本地字幕文件路径 (跳过下载/ASR，直接使用本地字幕)
LOCAL_SRT=
# 字幕语言 (逗号分隔或 "all")
SUB_LANGS=en
# 下载自动生成的字幕 (0=否, 1=是)
AUTO_SUBS=0
# 仅下载字幕，跳过视频下载 (0=否, 1=是)
SUBS_ONLY=0
# 不从源下载字幕，使用 ASR 生成 (0=下载源字幕, 1=使用 ASR)
NO_DOWNLOAD_SUBS=0
# yt-dlp 格式选择器
YTDLP_FORMAT=bestvideo+bestaudio/best
# yt-dlp 额外提取器参数 (可选)
EXTRACTOR_ARGS=
# 从浏览器加载 cookies (chrome/edge/firefox)
COOKIES_FROM_BROWSER=
# cookies 文件路径 (Netscape 格式)
COOKIES_FILE=config/cookies.txt

# =============================================================================
# ASR 语音识别配置 (WhisperX)
# =============================================================================

# Whisper 模型: large-v3, large-v2, medium, small, base, tiny
# large-v3 精度最高但最慢，tiny 最快但精度较低
ASR_MODEL=large-v3
# 计算设备: cuda (GPU) 或 cpu
ASR_DEVICE=cuda
# 转录批次大小 (显存不足时减小此值)
ASR_BATCH_SIZE=16
# 计算精度: float16, int8, int8_float16
# int8 节省显存但可能降低精度
ASR_COMPUTE_TYPE=float16
# 强制语言代码 (如 en, zh，留空自动检测)
ASR_LANGUAGE=
# Whisper 模型缓存目录
ASR_MODEL_DIR=checkpoints/whisper
# 跳过 ASR (即使没有可用字幕也跳过) (0=否, 1=是)
SKIP_ASR=0

# =============================================================================
# 多说话人配置 (说话人分离)
# =============================================================================

# 启用多说话人模式 (0=否, 1=是)
# 启用后，ASR 会识别不同说话人，TTS 会为每个说话人使用不同的参考音频
MULTI_SPEAKER=0
# HuggingFace token (多说话人模式必需)
# 获取地址: https://huggingface.co/settings/tokens
# 还需同意 pyannote 使用条款: https://huggingface.co/pyannote/speaker-diarization-3.1
HF_TOKEN=
# 说话人数量提示 (0=自动检测)
ASR_MIN_SPEAKERS=0
ASR_MAX_SPEAKERS=0
# 说话人名称映射 (逗号分隔，格式: ASR名称:参考音频文件夹名)
# 例如: SPEAKER_00:host,SPEAKER_01:guest
# 留空则使用 ASR 输出的说话人名称 (期望 ref/SPEAKER_00/, ref/SPEAKER_01/ 等)
SPEAKER_MAPPING=

# =============================================================================
# 翻译配置
# =============================================================================

# 目标语言
TARGET_LANGUAGE=Chinese
# 每次翻译的行数 (推荐 200)
TRANSLATE_CHUNK_SIZE=200
# 最大并发翻译任务数 (异步模式)
# 值越大越快，但可能触发 API 速率限制
TRANSLATE_MAX_CONCURRENT=5
# 单个翻译任务超时时间 (秒)
TRANSLATE_MAX_WAIT=300
# 轮询任务结果的间隔 (秒)
TRANSLATE_POLL_INTERVAL=2

# =============================================================================
# TTS 语音合成配置 (Fish Speech / OpenAudio)
# =============================================================================

# === 说话人配置 ===
# 默认说话人名称 (单人声模式使用，多人声模式作为后备)
TTS_SPEAKER=cxk

# === 参考音频文件夹结构 (统一格式) ===
# 所有模式都使用相同的文件夹结构:
#   ref/
#     {speaker_name}/
#       {speaker_name}.wav   <- 参考音频 (5-15秒清晰语音)
#       {speaker_name}.txt   <- 参考文本 (音频对应的文字内容)
#       {speaker_name}.npy   <- (可选，会自动生成的语音特征)
#
# 示例 - 单人声模式 (MULTI_SPEAKER=0):
#   ref/
#     cxk/
#       cxk.wav
#       cxk.txt
#
# 示例 - 多人声模式 (MULTI_SPEAKER=1):
#   ref/
#     SPEAKER_00/
#       SPEAKER_00.wav
#       SPEAKER_00.txt
#     SPEAKER_01/
#       SPEAKER_01.wav
#       SPEAKER_01.txt
#
# 使用 SPEAKER_MAPPING 映射时:
#   SPEAKER_MAPPING=SPEAKER_00:host,SPEAKER_01:guest
#   ref/
#     host/
#       host.wav
#       host.txt
#     guest/
#       guest.wav
#       guest.txt
#
# 注意: 如果 ASR 检测到的说话人比 ref 中多，
#       缺失的说话人会使用第一个成功使用的参考音频

# === 模型路径 ===
# DAC 音频编解码器检查点路径
TTS_DAC_CHECKPOINT=checkpoints/openaudio-s1-mini/codec.pth
# 文本转语义模型检查点目录
TTS_T2S_CHECKPOINT=checkpoints/openaudio-s1-mini
# 计算设备: cuda (GPU) 或 cpu
TTS_DEVICE=cuda

# === 生成参数 ===
# 温度: 值越低生成越确定，减少参考内容泄露
TTS_TEMPERATURE=0.3
# Top-P 采样: 值越低采样范围越窄，输出更稳定
TTS_TOP_P=0.7
# 重复惩罚: 值越高越不容易重复，防止参考内容被复读
TTS_REPETITION_PENALTY=1.2
# 随机种子 (用于可复现的生成结果)
TTS_SEED=42
# 精度模式: 1=强制 float16, 0=使用 bfloat16
TTS_HALF=0
# 启用 torch.compile 优化 (0=否, 1=是)
# 首次运行会较慢，后续运行更快
TTS_COMPILE=0
# TTS 音频音量倍数
TTS_VOLUME=1.0

# =============================================================================
# 视频合成配置 (FFmpeg)
# =============================================================================

# 音频模式:
#   replace - 仅使用 TTS 音频 (完全替换原音)
#   mix     - 混合 TTS 和降低音量的原音
#   bgm     - 混合 TTS 和背景音乐 (需要人声分离)
AUDIO_MODE=replace
# 原音音量倍数 (mix 模式使用)
ORIGINAL_VOLUME=0.2
# 是否烧录字幕到视频 (0=否, 1=是)
BURN_SUBS=1
# 音频重叠处理策略:
#   truncate - 截断超出时间的音频
#   speed    - 加速音频以适应时间
#   hybrid   - 混合策略 (短重叠截断，长重叠加速)
#   none     - 不处理重叠
OVERLAP_STRATEGY=hybrid
# 最大 TTS 加速倍数 (speed/hybrid 策略使用)
MAX_TTS_SPEED=1.5
# 人声分离方法 (bgm 模式使用): demucs | spleeter
SEPARATION_METHOD=demucs

# =============================================================================
# 字幕样式配置 (ASS 格式)
# =============================================================================

# 每行最大字符数 (中文=1.0 宽度单位, ASCII=0.5 宽度单位)
SUB_MAX_LINE_WIDTH=22
# 每条字幕最大行数 (0=不限制)
SUB_MAX_LINES=2
# 字体名称
SUB_FONT_NAME=Microsoft YaHei
# 字体大小 (像素)
SUB_FONT_SIZE=52
# 粗体 (0=否, 1=是)
SUB_BOLD=0
# 斜体 (0=否, 1=是)
SUB_ITALIC=0
# 文字颜色 (ASS 格式 &HBBGGRR，注意是 BGR 顺序!)
# 白色=&H00FFFFFF, 黄色=&H0000FFFF
SUB_PRIMARY_COLOR=&H00FFFFFF
# 次要颜色 (ASS 格式 &HBBGGRR，用于卡拉OK效果)
SUB_SECONDARY_COLOR=&H000000FF
# 描边颜色 (ASS 格式 &HBBGGRR)
# 黑色=&H00000000
SUB_OUTLINE_COLOR=&H00000000
# 阴影/背景颜色 (ASS 格式 &HAABBGGRR，带透明度)
# 半透明黑色=&H80000000
SUB_BACK_COLOR=&H80000000
# 描边宽度 (像素)
SUB_OUTLINE=2
# 阴影深度 (像素)
SUB_SHADOW=1
# 对齐方式: 1=左对齐, 2=居中, 3=右对齐 (底部行)
SUB_ALIGNMENT=2
# 左边距 (像素)
SUB_MARGIN_L=30
# 右边距 (像素)
SUB_MARGIN_R=30
# 底部垂直边距 (像素)
SUB_MARGIN_V=25
# 边框样式: 1=描边+阴影, 3=不透明背景框
SUB_BORDER_STYLE=1

# =============================================================================
# 其他配置
# =============================================================================

# SRT 处理时保留短行的最小字符数 (低于此值会与相邻行合并)
SRT_MIN_CHARS=0
# 调试模式 (0=否, 1=是)
# 启用后输出更多调试信息
DEBUG=0
